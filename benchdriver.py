import os
import csv
import logging
from Settings import RESULTS_FILENAME, DATA_SIZE, NUM_BENCH_ITERATIONS
import ArgoQueries
import MongoQueries
import PJsonQueries

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

class ResultsFileHandler:
    def __init__(self, filename):
        self.filename = filename

    def write_header(self, system, data_size):
        with open(self.filename, 'w') as csvfile:
            writer = csv.writer(csvfile, delimiter=',',)
            writer.writerow(['System', system])
            writer.writerow(['Data_Size', data_size])

    def write_row(self, results_list):
        with open(self.filename, 'a') as csvfile:
            writer = csv.writer(csvfile, delimiter=',',)
            writer.writerow(results_list)


class TestSuite:
    def __init__(
        self,
        tag,
        loader,
        cleaner,
        queries_array,
        include_indexes=range(0,12),
        skip_indexes=[],
        obj_count=DATA_SIZE,
    ):
        self.obj_count = obj_count
        self.loader = loader
        self.cleaner = cleaner
        self.tag = tag

        query_indexes = [i for i in include_indexes if i not in skip_indexes]
        if max(query_indexes) > len(queries_array):
            raise IndexError('Requested index greater than number of queries')

        self.queries = [queries_array[i] for i in query_indexes]
        self.query_numbers = [i+1 for i in query_indexes]

        # CSV results file writer
        split_filename = RESULTS_FILENAME.split(".")
        results_filename = "{prefix}_{data_size}_{system}.{extension}".format(
            prefix=split_filename[0],
            data_size=str(self.obj_count),
            system=self.tag,
            extension=split_filename[1],
        )
        self.results = ResultsFileHandler(results_filename)

        self.results.write_header(self.tag, str(self.obj_count))

    def load_data(self):
        load_time = self.loader.execute()
        self.results.write_row(['Load_time', str(load_time)])

    def clean(self):
        self.cleaner.execute()

    def run_bench_queries(self, num_iterations=1):
        queries_header = ['Q'+str(i) for i in self.query_numbers]
        self.results.write_row(queries_header)

        for iteration in xrange(num_iterations):
            results = []
            for query in self.queries:
                results.append(query.execute())
            self.results.write_row(results)

###
# Wipe out JSON Documents generated by nobench_data_gen
###
def remove_json_docs():
    import Settings
    files = [Settings.MONGO_FILENAME, Settings.MONGO_EXTRA_FILENAME, Settings.ARGO_EXTRA_FILENAME, Settings.ARGO_FILENAME]

    for filename in files:
        if os.path.exists(filename):
            os.remove(filename)


if __name__ == "__main__":
    q1a = ArgoQueries.Query1Argo()
    q2a = ArgoQueries.Query2Argo()
    q3a = ArgoQueries.Query3Argo()
    q4a = ArgoQueries.Query4Argo()
    q5a = ArgoQueries.Query5Argo()
    q6a = ArgoQueries.Query6Argo()
    q7a = ArgoQueries.Query7Argo()
    q8a = ArgoQueries.Query8Argo()
    q9a = ArgoQueries.Query9Argo()
    q10a = ArgoQueries.Query10Argo()
    q11a = ArgoQueries.Query11Argo()
    q12a = ArgoQueries.Query12Argo()
    q13a = ArgoQueries.Query13Argo()
    q14a = ArgoQueries.Query14Argo()
    argo_loader = ArgoQueries.InitialLoadArgo()
    argo_dropper = ArgoQueries.DropCollectionArgo()
    argo_queries = [q1a, q2a, q3a, q4a, q5a, q6a, q7a, q8a, q9a, q10a, q11a, q12a, q13a, q14a]
    argo_include_indexes = range(0,12)
    argo_skip_indexes = [10]
    argo_test_suite = TestSuite(
        tag='Argo',
        loader=argo_loader,
        cleaner=argo_dropper,
        queries_array=argo_queries,
        include_indexes=argo_include_indexes,
        skip_indexes=argo_skip_indexes,
    )

    q1m = MongoQueries.Query1Mongo()
    q2m = MongoQueries.Query2Mongo()
    q3m = MongoQueries.Query3Mongo()
    q4m = MongoQueries.Query4Mongo()
    q5m = MongoQueries.Query5Mongo()
    q6m = MongoQueries.Query6Mongo()
    q7m = MongoQueries.Query7Mongo()
    q8m = MongoQueries.Query8Mongo()
    q9m = MongoQueries.Query9Mongo()
    q10m = MongoQueries.Query10Mongo()
    q11m = MongoQueries.Query11Mongo()
    q12m = MongoQueries.Query12Mongo()
    q13m = MongoQueries.Query13Mongo()
    q14m = MongoQueries.Query14Mongo()
    mongo_loader = MongoQueries.InitialLoadMongo()
    mongo_dropper = MongoQueries.DropCollectionMongo()
    mongo_queries = [q1m, q2m, q3m, q4m, q5m, q6m, q7m, q8m, q9m, q10m, q11m, q12m, q13m, q14m]
    mongo_include_indexes = range(0,12)
    mongo_skip_indexes = [10]
    mongo_test_suite = TestSuite(
        tag='Mongo',
        loader=mongo_loader,
        cleaner=mongo_dropper,
        queries_array=mongo_queries,
        include_indexes=mongo_include_indexes,
        skip_indexes=mongo_skip_indexes,
    )

    q1p = PJsonQueries.Query1PJson()
    q2p = PJsonQueries.Query2PJson()
    q3p = PJsonQueries.Query3PJson()
    q4p = PJsonQueries.Query4PJson()
    q5p = PJsonQueries.Query5PJson()
    q6p = PJsonQueries.Query6PJson()
    q7p = PJsonQueries.Query7PJson()
    q8p = PJsonQueries.Query8PJson()
    q9p = PJsonQueries.Query9PJson()
    q10p = PJsonQueries.Query10PJson()
    q11p = PJsonQueries.Query11PJson()
    q12p = PJsonQueries.Query12PJson()
    q13p = PJsonQueries.Query13PJson()
    q14p = PJsonQueries.Query14PJson()
    pjson_loader = PJsonQueries.InitialLoadPJson()
    pjson_dropper = PJsonQueries.DropCollectionPJson()
    pjson_queries = [q1p, q2p, q3p, q4p, q5p, q6p, q7p, q8p, q9p, q10p, q11p, q12p, q13p, q14p]
    pjson_include_indexes = range(0,14)
    pjson_skip_indexes = []
    pjson_test_suite = TestSuite(
        tag='PJson',
        loader=pjson_loader,
        cleaner=pjson_dropper,
        queries_array=pjson_queries,
        include_indexes=pjson_include_indexes,
        skip_indexes=pjson_skip_indexes,
    )

    run_argo_bench = False
    run_mongo_bench = False
    run_pjson_bench = True

    #################################
    #Actual testing area begins here.
    #################################
    if run_argo_bench:
        generate_argo_data = False
        load_argo_data = True
        log.info("Beginning Argo Benchmark.")
        if generate_argo_data:
            log.info("Argo Generate new Data flag was true. Attempting to remove JSON docs.")
            remove_json_docs()
            log.info("Generating new data of size: {}.".format(DATA_SIZE))
            ArgoQueries.generate_data_argo(DATA_SIZE)
        if load_argo_data:
            log.info("Cleaning out Argo PostgreSQL.")
            argo_test_suite.clean()
            log.info("Loading new data into Argo PostgreSQL.")
            argo_test_suite.load_data()
        log.info("Running Argo Benchmark Queries.")
        results = argo_test_suite.begin_testing(NUM_BENCH_ITERATIONS)
        log.info("Argo testing suite complete. ")


    if run_mongo_bench:
        generate_mongo_data = False
        load_mongo_data = True
        log.info("Beginning Mongo Benchmark.")
        if generate_mongo_data:
            log.info("Mongo Generate new Data flag was true.")
            remove_json_docs()
            log.info("Generating new data of size: {}.".format(DATA_SIZE))
            MongoQueries.generate_data_mongo(DATA_SIZE)
        if load_mongo_data:
            log.info("Cleaning out MongoDB.")
            mongo_test_suite.clean()
            log.info("Loading new data into MongoDB.")
            mongo_test_suite.load_data()
        log.info("Running Mongo Benchmark Queries.")
        results = mongo_test_suite.run_bench_queries(NUM_BENCH_ITERATIONS)
        log.info("Mongo testing suite complete. ")


    if run_pjson_bench:
        generate_pjson_data = False
        load_pjson_data = True
        log.info("Beginning Mongo Benchmark.")
        if generate_pjson_data:
            log.info("PJSON Generate new Data flag was true. Using Mongo's data.")
        if load_pjson_data:
            log.info("Cleaning out PostgreSQL JSONB.")
            pjson_test_suite.clean()
            log.info("Loading new data into PostgreSQL JSONB.")
            pjson_test_suite.load_data()
        log.info("Running PJson Benchmark Queries.")
        results = pjson_test_suite.run_bench_queries(NUM_BENCH_ITERATIONS)
        log.info("PJson testing suite complete. ")
